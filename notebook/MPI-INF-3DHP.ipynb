{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from tqdm import tqdm\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = 'D:/data/MPI-INF-3DHP'\n",
    "\n",
    "available_subject = [1, 2, ]\n",
    "available_sequence = [1, 2, ]\n",
    "available_camera = [camera for camera in range(14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SequentialDictionary:\n",
    "    '''The custom dictionary class\n",
    "    \n",
    "    You can use a dictionary with multiple indices, i.e. x['1st dim']['2nd dim'] = 2.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = dict()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if index not in self.data.keys():\n",
    "            self.data[index] = SequentialDictionary()\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __setitem__(self, index, value):\n",
    "        self.data[index] = value\n",
    "    \n",
    "    def __len__(self):\n",
    "        length = 0\n",
    "        for key, value in self.data.items():\n",
    "            if type(value) is SequentialDictionary:\n",
    "                length = length + len(value)\n",
    "            else:\n",
    "                length = length + 1\n",
    "        return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video\n",
    "VIDEO_RGB = 'imageSequence'\n",
    "VIDEO_MASK_HUMAN_AND_CHAIR = 'FGmasks'\n",
    "VIDEO_MASK_CHAIR = 'ChairMasks'\n",
    "\n",
    "available_format = [\n",
    "    VIDEO_RGB,\n",
    "    VIDEO_MASK_HUMAN_AND_CHAIR,\n",
    "    VIDEO_MASK_CHAIR,\n",
    "]\n",
    "\n",
    "video_path = '{root}/{subject}/{sequence}/{format}/video_{camera}.avi'\n",
    "video = SequentialDictionary()\n",
    "\n",
    "available_video = product(*[\n",
    "    available_subject, \n",
    "    available_sequence, \n",
    "    available_format, \n",
    "    available_camera,\n",
    "])\n",
    "total = len(available_subject) * len(available_sequence) * len(available_format) * len(available_camera)\n",
    "\n",
    "for subject, sequence, format, camera in tqdm(available_video, total=total):\n",
    "    video[subject][sequence][format][camera] = cv.VideoCapture(video_path.format(\n",
    "        root=root,\n",
    "        subject='S%d' % subject,\n",
    "        sequence='Seq%d' % sequence,\n",
    "        format=format,\n",
    "        camera=camera,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation\n",
    "ANNOT_CAMERA_2D = 'annot2'\n",
    "ANNOT_CAMERA_3D = 'annot3'\n",
    "ANNOT_WORLD_3D = 'univ_annot3'\n",
    "ANNOT_CAMERA_CALI = 'cameras'\n",
    "\n",
    "annot_path = '{root}/{subject}/{sequence}/annot.mat'\n",
    "annot = SequentialDictionary()\n",
    "\n",
    "available_annot = product(*[\n",
    "    available_subject, \n",
    "    available_sequence,\n",
    "])\n",
    "total = len(available_subject) * len(available_sequence)\n",
    "\n",
    "for subject, sequence, in tqdm(available_annot, total=total):\n",
    "    annot[subject][sequence] = scipy.io.loadmat(annot_path.format(\n",
    "        root=root,\n",
    "        subject='S%d' % subject,\n",
    "        sequence='Seq%d' % sequence,\n",
    "    ))\n",
    "    progress.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera parameters\n",
    "CAMERA_INTRINSIC = 'intrinsic'\n",
    "CAMERA_EXTRINSIC = 'extrinsic'\n",
    "\n",
    "camera_path = '{root}/{subject}/{sequence}/camera.calibration'\n",
    "camera_parameter = SequentialDictionary()\n",
    "\n",
    "available_camera_parameter = product(*[\n",
    "    available_subject, \n",
    "    available_sequence,\n",
    "])\n",
    "total = len(available_subject) * len(available_sequence)\n",
    "\n",
    "for subject, sequence, in tqdm(available_camera_parameter, total=total):\n",
    "    camera_index = -1\n",
    "    with open(camera_path.format(\n",
    "        root=root,\n",
    "        subject='S%d' % subject,\n",
    "        sequence='Seq%d' % sequence,\n",
    "    ), 'r') as file:\n",
    "        for line in file:\n",
    "            word = line.strip().split() # remove whilespace\n",
    "\n",
    "            if word[0] == 'name':\n",
    "                camera_index = int(word[-1])\n",
    "\n",
    "            elif word[0] == CAMERA_INTRINSIC:\n",
    "                mat = np.reshape(np.asarray(word[1:], dtype=np.float), newshape=(4, 4))\n",
    "                mat = mat[0:3, 0:3]\n",
    "                camera_parameter[subject][sequence][camera_index][CAMERA_INTRINSIC] = mat\n",
    "            elif word[0] == CAMERA_EXTRINSIC:\n",
    "                mat = np.reshape(np.asarray(word[1:], dtype=np.float), newshape=(4, 4))\n",
    "                mat = mat[0:3, 0:4]\n",
    "                camera_parameter[subject][sequence][camera_index][CAMERA_EXTRINSIC] = mat\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 2\n",
    "sequence = 2\n",
    "camera = 8\n",
    "frame = 572\n",
    "\n",
    "image = SequentialDictionary()\n",
    "for format in available_format:\n",
    "    video[subject][sequence][format][camera].set(cv.CAP_PROP_POS_FRAMES, frame)\n",
    "    success, image[format] = video[subject][sequence][format][camera].read()\n",
    "    assert success\n",
    "\n",
    "in_3D = np.reshape(annot[subject][sequence][ANNOT_CAMERA_3D][camera, 0][frame], newshape=(-1, 3))\n",
    "\n",
    "num_keypoints = len(in_3D)\n",
    "\n",
    "# reshape for easy matrix multiplication\n",
    "in_3D = np.concatenate((in_3D, np.ones(shape=(num_keypoints, 1))), axis=1).transpose(1, 0)\n",
    "identity_transform = np.concatenate((np.eye(3), np.ones(shape=(3, 1))), axis=1)\n",
    "\n",
    "projected = np.matmul(identity_transform, in_3D)\n",
    "projected = np.matmul(camera_parameter[subject][sequence][camera][CAMERA_INTRINSIC], projected)\n",
    "projected = projected / projected[-1, :]\n",
    "projected = projected.transpose(1, 0)\n",
    "\n",
    "for keypoint in projected:\n",
    "    x, y, _ = keypoint\n",
    "    \n",
    "    for tx in range(-10, 10):\n",
    "        for ty in range(-10, 10):\n",
    "            xx = x + tx\n",
    "            yy = y + ty\n",
    "            \n",
    "            if xx < 0 or image[VIDEO_RGB].shape[1] <= xx \\\n",
    "            or yy < 0 or image[VIDEO_RGB].shape[0] <= yy:\n",
    "                continue\n",
    "            \n",
    "            image[VIDEO_RGB][int(yy), int(xx), :] = [255, 0, 0]\n",
    "\n",
    "            \n",
    "for format in available_format:\n",
    "    success = cv.imwrite('{format}.jpg'.format(format=format), image[format])\n",
    "    assert success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "available_video = product(*[\n",
    "    available_subject, \n",
    "    available_sequence, \n",
    "    available_format, \n",
    "    available_camera,\n",
    "])\n",
    "\n",
    "for subject, sequence, format, camera in available_video:\n",
    "    video[subject][sequence][format][camera].release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Video:', video_path)\n",
    "# print('Open:', video.isOpened())\n",
    "# print('Resolution:', '%dx%d' % (video.get(cv.CAP_PROP_FRAME_WIDTH), video.get(cv.CAP_PROP_FRAME_HEIGHT)))\n",
    "# print('Total frames:', video.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "# print('Frame-rate:', video.get(cv.CAP_PROP_FPS))\n",
    "# print('OpenCV:', cv.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
