{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "import cv2\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "from functools import lru_cache\n",
    "from tqdm import tqdm as tqdm\n",
    "from vectormath import Vector2\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class H36Mparser(object):\n",
    "    data = [\n",
    "        'S',\n",
    "        'center',\n",
    "        'part',\n",
    "        'scale',\n",
    "        'zind',\n",
    "    ]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.annotation = h5py.File('C:/Users/I.B. Park/Desktop/h36m/annot/train.h5', 'r')\n",
    "        self.image_name = np.genfromtxt('C:/Users/I.B. Park/Desktop/h36m/annot/train_images.txt', dtype = str)\n",
    "        self.shuffle = np.arange(len(self))\n",
    "    \n",
    "    @lru_cache(maxsize=1)\n",
    "    def __len__(self):\n",
    "        return len(self.image_name)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.index = 0\n",
    "        np.random.shuffle(self.shuffle)\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.index >= len(self):\n",
    "            raise StopIteration\n",
    "        index = self.shuffle[self.index]\n",
    "        self.index = self.index + 1\n",
    "        return [self.annotation[tag][index] for tag in H36Mparser.data] + [self.image_name[index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=32)\n",
    "def gaussian(size, sigma=0.25, mean=0.5):\n",
    "    width = size\n",
    "    heigth = size\n",
    "    amplitude = 1.0\n",
    "    sigma_u = sigma\n",
    "    sigma_v = sigma\n",
    "    mean_u = mean * width + 0.5\n",
    "    mean_v = mean * heigth + 0.5\n",
    "\n",
    "    over_sigma_u = 1.0 / (sigma_u * width)\n",
    "    over_sigma_v = 1.0 / (sigma_v * heigth)\n",
    "\n",
    "    x = np.arange(0, width, 1, np.float32)\n",
    "    y = x[:, np.newaxis]\n",
    "\n",
    "    du = (x + 1 - mean_u) * over_sigma_u\n",
    "    dv = (y + 1 - mean_v) * over_sigma_v\n",
    "\n",
    "    return amplitude * np.exp(-0.5 * (du * du + dv * dv))\n",
    "\n",
    "\n",
    "def generateHeatmap(size, y0, x0, sigma=1):\n",
    "    pad = 3 * sigma\n",
    "    y0, x0 = int(y0), int(x0)\n",
    "    dst = [max(0, y0 - pad), max(0, min(size, y0 + pad + 1)), max(0, x0 - pad), max(0, min(size, x0 + pad + 1))]\n",
    "    src = [-min(0, y0 - pad), pad + min(pad, size - y0 - 1) + 1, -min(0, x0 - pad), pad + min(pad, size - x0 - 1) + 1]\n",
    "\n",
    "    heatmap = np.zeros([size, size])\n",
    "    g = gaussian(3 * 2 * sigma + 1)\n",
    "    heatmap[dst[0]:dst[1], dst[2]:dst[3]] = g[src[0]:src[1], src[2]:src[3]]\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "def cropImage(image, center, scale, rotate, resolution):\n",
    "    center = Vector2(center)  # assign new array\n",
    "    height, width, _ = image.shape\n",
    "    crop_ratio = 200 * scale / resolution\n",
    "    if crop_ratio >= 2:  # if box size is greater than two time of resolution px\n",
    "        # scale down image\n",
    "        height = math.floor(height / crop_ratio)\n",
    "        width = math.floor(width / crop_ratio)\n",
    "\n",
    "        if max([height, width]) < 2:\n",
    "            # Zoomed out so much that the image is now a single pixel or less\n",
    "            raise ValueError(\"Width or height is invalid!\")\n",
    "\n",
    "        image = skimage.transform.resize(image, (height, width), mode='constant')\n",
    "        center /= crop_ratio\n",
    "        scale /= crop_ratio\n",
    "\n",
    "    ul = (center - 200 * scale / 2).astype(int)\n",
    "    br = (center + 200 * scale / 2).astype(int)  # Vector2\n",
    "\n",
    "    if crop_ratio >= 2:  # force image size 256 x 256\n",
    "        br -= (br - ul - resolution)\n",
    "\n",
    "    pad_length = math.ceil((ul - br).length - (br.x - ul.x) / 2)\n",
    "\n",
    "    if rotate != 0:\n",
    "        ul -= pad_length\n",
    "        br += pad_length\n",
    "\n",
    "    src = [max(0, ul.y), min(height, br.y), max(0, ul.x), min(width, br.x)]\n",
    "    dst = [max(0, -ul.y), min(height, br.y) - ul.y, max(0, -ul.x), min(width, br.x) - ul.x]\n",
    "\n",
    "    new_image = np.zeros([br.y - ul.y, br.x - ul.x, 3], dtype=np.float64)\n",
    "    new_image[dst[0]:dst[1], dst[2]:dst[3], :] = image[src[0]:src[1], src[2]:src[3], :]\n",
    "\n",
    "    if rotate != 0:\n",
    "        new_image = skimage.transform.rotate(new_image, rotate)\n",
    "        new_height, new_width, _ = new_image.shape\n",
    "        new_image = new_image[pad_length:new_height - pad_length, pad_length:new_width - pad_length, :]\n",
    "\n",
    "    if crop_ratio < 2:\n",
    "        new_image = skimage.transform.resize(new_image, (resolution, resolution), mode='constant')\n",
    "\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateVoxel(voxel_xy_resolution, voxel_z_resolution, xy, z, heatmap_xy_coefficient, heatmap_z_coefficient):\n",
    "    volume = np.ndarray(shape = (voxel_xy_resolution, voxel_xy_resolution, voxel_z_resolution), dtype = np.float64)\n",
    "    xy_view = generateHeatmap(size = voxel_xy_resolution, y0 = xy[1], x0 = xy[0], sigma = heatmap_xy_coefficient)\n",
    "    z_view = gaussian(heatmap_z_coefficient)[math.ceil(heatmap_z_coefficient/2) - 1]\n",
    "    cnt = 0\n",
    "    for i in range(z - math.floor(heatmap_z_coefficient/2), z + math.floor(heatmap_z_coefficient/2) + 1):\n",
    "        if 0 <= i < voxel_z_resolution:\n",
    "            volume[:, :, i] = z_view[cnt] * xy_view\n",
    "        cnt = cnt + 1\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_image_name(image_name):\n",
    "    subject_action, camera_frame, _ = image_name.split('.')\n",
    "    split = subject_action.split('_')\n",
    "    subject = split[0]\n",
    "    action = split[1]\n",
    "    if len(split) >= 3:\n",
    "        action = action + '_' + split[2]\n",
    "    camera, frame = camera_frame.split('_')\n",
    "    \n",
    "    return subject, action, camera, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = H36Mparser()\n",
    "\n",
    "z_limits = np.squeeze(scipy.io.loadmat('C:/Users/I.B. Park/Desktop/c2f-vol-demo-master/matlab/utils/data/voxel_limits.mat')['limits'])\n",
    "z_centers = (z_limits[1:65] + z_limits[0:64]) / 2\n",
    "z_delta = z_limits[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'D:/data/Human3.6M/converted'\n",
    "\n",
    "# Voxel heatmap sigma.\n",
    "heatmap_xy_coefficient = 2\n",
    "heatmap_z_coefficient = -1\n",
    "\n",
    "# Voxel resolution.\n",
    "voxel_xy_resolution = 64\n",
    "voxel_z_fine_resolution = 64\n",
    "voxel_z_coarse_resolution = -1\n",
    "\n",
    "voxel_z_resolutions = [1, 2, 4, voxel_z_fine_resolution]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(features = 256, joints = len(parser.annotation['zind'][0]), z_resolutions = voxel_z_resolutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(model.z_resolutions)\\nfor stage, _ in enumerate(model.z_resolutions):\\n    print(model.voxel_groundtruth[stage], model.voxels[stage])\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(model.z_resolutions)\n",
    "for stage, _ in enumerate(model.z_resolutions):\n",
    "    print(model.voxel_groundtruth[stage], model.voxels[stage])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                            | 0/312188 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Tensor must be 4-D with last dim 1, 3, or 4, not [1,64,17]\n\t [[Node: voxel_1D_01 = ImageSummary[T=DT_FLOAT, bad_color=Tensor<type: uint8 shape: [4] values: 255 0 0...>, max_images=3, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](voxel_1D_01/tag, strided_slice/_423)]]\n\nCaused by op 'voxel_1D_01', defined at:\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-05fab97810e4>\", line 1, in <module>\n    model = Model(features = 256, joints = len(parser.annotation['zind'][0]), z_resolutions = voxel_z_resolutions)\n  File \"C:\\Users\\I.B. Park\\Desktop\\Pose3D\\model.py\", line 61, in __init__\n    tf.summary.image('voxel_%dD_%02d' % (z_resolution, z+1), self.voxels[stage][:, :, z])\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\summary\\summary.py\", line 184, in image\n    name=scope)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_logging_ops.py\", line 190, in _image_summary\n    name=name)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Tensor must be 4-D with last dim 1, 3, or 4, not [1,64,17]\n\t [[Node: voxel_1D_01 = ImageSummary[T=DT_FLOAT, bad_color=Tensor<type: uint8 shape: [4] values: 255 0 0...>, max_images=3, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](voxel_1D_01/tag, strided_slice/_423)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Tensor must be 4-D with last dim 1, 3, or 4, not [1,64,17]\n\t [[Node: voxel_1D_01 = ImageSummary[T=DT_FLOAT, bad_color=Tensor<type: uint8 shape: [4] values: 255 0 0...>, max_images=3, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](voxel_1D_01/tag, strided_slice/_423)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0b96388f8f73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 _, result, summary, step = sess.run([optimizer, loss, summary_merged, tf.train.get_global_step()],\n\u001b[1;32m---> 92\u001b[1;33m                                                     feed_dict=feed)\n\u001b[0m\u001b[0;32m     93\u001b[0m                 \u001b[0mprogress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[0mprogress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epoch: %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mc:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Tensor must be 4-D with last dim 1, 3, or 4, not [1,64,17]\n\t [[Node: voxel_1D_01 = ImageSummary[T=DT_FLOAT, bad_color=Tensor<type: uint8 shape: [4] values: 255 0 0...>, max_images=3, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](voxel_1D_01/tag, strided_slice/_423)]]\n\nCaused by op 'voxel_1D_01', defined at:\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-05fab97810e4>\", line 1, in <module>\n    model = Model(features = 256, joints = len(parser.annotation['zind'][0]), z_resolutions = voxel_z_resolutions)\n  File \"C:\\Users\\I.B. Park\\Desktop\\Pose3D\\model.py\", line 61, in __init__\n    tf.summary.image('voxel_%dD_%02d' % (z_resolution, z+1), self.voxels[stage][:, :, z])\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\summary\\summary.py\", line 184, in image\n    name=scope)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_logging_ops.py\", line 190, in _image_summary\n    name=name)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"c:\\users\\i.b. park\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Tensor must be 4-D with last dim 1, 3, or 4, not [1,64,17]\n\t [[Node: voxel_1D_01 = ImageSummary[T=DT_FLOAT, bad_color=Tensor<type: uint8 shape: [4] values: 255 0 0...>, max_images=3, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](voxel_1D_01/tag, strided_slice/_423)]]\n"
     ]
    }
   ],
   "source": [
    "# with tf.Session() as sess:\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "with tf.variable_scope('loss'):\n",
    "    loss = sum([\n",
    "        tf.losses.mean_squared_error(\n",
    "            tf.reshape(model.voxel_groundtruth[stage], shape=[-1, 64 * 64, model.joints * z_resolution]),\n",
    "            tf.reshape(model.voxels[stage], shape=[-1, 64 * 64, model.joints * z_resolution]))\n",
    "        for stage, z_resolution in enumerate(model.z_resolutions)\n",
    "    ])\n",
    "\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        optimizer = tf.train.RMSPropOptimizer(name='optimizer', learning_rate=2.5e-4).minimize(loss, global_step=global_step)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    summary_merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter('log', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    saver = tf.train.Saver(max_to_keep=10)\n",
    "\n",
    "    # if MODEL.pretrained.is_using:\n",
    "    #     saver.restore(sess, os.path.join(MODEL.pretrained.path, '%s.ckpt' % file_name))\n",
    "\n",
    "\n",
    "    tf.train.global_step(sess, global_step)\n",
    "    for epoch in range(3):\n",
    "        with tqdm(range(len(parser))) as progress:\n",
    "            progress.set_description('Epoch(%d)' % epoch)\n",
    "\n",
    "            for S, center, part, scale, zind, image_name in parser:\n",
    "                voxels = list()\n",
    "\n",
    "                # Extract subject and camera name from an image name.\n",
    "                subject, _, camera, _ = decode_image_name(image_name)\n",
    "\n",
    "                # Pre-calculate constants.\n",
    "                image_xy_resolution = 200 * scale\n",
    "\n",
    "                # Crop RGB image.\n",
    "                image = skimage.io.imread('%s/%s-2/%s' % (data_dir, subject, image_name))\n",
    "                image = cropImage(image, center, scale, 0, 256)\n",
    "                # imageio.imwrite('rgb.png', image)\n",
    "\n",
    "                # Build voxel.\n",
    "                for voxel_z_coarse_resolution in voxel_z_resolutions:\n",
    "                    # heatmap_z_coefficient is 1, 1, 1, 3, 5, 7, 13 for 1, 2, 4, 8, 16, 32, 64.\n",
    "                    heatmap_z_coefficient = 2 * math.floor((6 * heatmap_xy_coefficient * voxel_z_coarse_resolution / voxel_z_fine_resolution + 1)/2) + 1\n",
    "\n",
    "                    # Convert the coordinate from a RGB image to a cropped RGB image.\n",
    "                    xy = voxel_xy_resolution * (part - center) / image_xy_resolution + voxel_xy_resolution * 0.5\n",
    "\n",
    "                    voxel = np.ndarray(shape = (voxel_xy_resolution, voxel_xy_resolution, len(part) * voxel_z_coarse_resolution))\n",
    "                    for part_idx in range(len(part)):\n",
    "                        # zind range (1, 64)\n",
    "                        # z range (0, 63)\n",
    "                        z = math.ceil(zind[part_idx] * voxel_z_coarse_resolution / voxel_z_fine_resolution) - 1\n",
    "                        voxel[:, :, part_idx * voxel_z_coarse_resolution : (part_idx + 1) * voxel_z_coarse_resolution] = generateVoxel(\n",
    "                            voxel_xy_resolution, voxel_z_coarse_resolution,\n",
    "                            xy[part_idx], z,\n",
    "                            heatmap_xy_coefficient, heatmap_z_coefficient)\n",
    "                    voxels.append(voxel)\n",
    "\n",
    "                    '''\n",
    "                    for z in range(voxel_z_coarse_resolution):\n",
    "                        for y in range(voxel_xy_resolution):\n",
    "                            for x in range(voxel_xy_resolution):\n",
    "                                voxel[y, x, z] = np.max(voxel[y, x, [part * voxel_z_coarse_resolution + z for part in range(len(part))]])\n",
    "                    for z in range(voxel_z_coarse_resolution):\n",
    "                        imageio.imwrite('%02d_%02d.png' % (voxel_z_coarse_resolution, z), voxel[:, :, z])\n",
    "                    '''\n",
    "\n",
    "                train_images = np.ndarray(shape=(1, 256, 256, 3), dtype = np.float64)\n",
    "                train_voxels = [np.ndarray(shape=(1, 64, 64, len(parser.annotation['zind'][0]) * z_resolution), dtype = np.float64)\n",
    "                                for z_resolution in voxel_z_resolutions]\n",
    "                train_images[0, :, :, :] = image\n",
    "                for stage in range(len(voxel_z_resolutions)):\n",
    "                    train_voxels[stage][0, :, :, :] = voxels[stage]\n",
    "\n",
    "                feed = dict()\n",
    "                feed[model.images] = train_images\n",
    "                for stage in range(len(voxel_z_resolutions)):\n",
    "                    feed[model.voxel_groundtruth[stage]] = train_voxels[stage]\n",
    "                feed[model.is_training] = True\n",
    "\n",
    "\n",
    "\n",
    "                _, result, summary, step = sess.run([optimizer, loss, summary_merged, tf.train.get_global_step()],\n",
    "                                                    feed_dict=feed)\n",
    "                progress.set_postfix(loss=result)\n",
    "                progress.set_description(\"epoch: %d\" % epoch)\n",
    "                progress.update(1)\n",
    "\n",
    "                writer.add_summary(summary, step)\n",
    "\n",
    "        save_path = saver.save('save_%03d.ckpt' % (math.round(step / len(parser))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
